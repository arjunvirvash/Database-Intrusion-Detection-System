{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11177162,"sourceType":"datasetVersion","datasetId":6600143},{"sourceId":11214656,"sourceType":"datasetVersion","datasetId":6285951},{"sourceId":11289304,"sourceType":"datasetVersion","datasetId":7002085}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:32:05.729669Z","iopub.execute_input":"2025-04-05T19:32:05.730023Z","iopub.status.idle":"2025-04-05T19:32:05.777865Z","shell.execute_reply.started":"2025-04-05T19:32:05.729994Z","shell.execute_reply":"2025-04-05T19:32:05.776733Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/capsnet-lstm-dataset/malicious.csv\n/kaggle/input/capsnet-lstm-dataset/testing_queries.csv\n/kaggle/input/capsnet-lstm-dataset/test_data_correct.csv\n/kaggle/input/capsnet-lstm-dataset/train_data.csv\n/kaggle/input/capsnet-lstm-dataset/test_data.csv\n/kaggle/input/capsnet-lstm-dataset/normal.csv\n/kaggle/input/capsnet-lstm-dataset/training_queries.csv\n/kaggle/input/rnp-miner-dataset/RNP-Miner_3.py\n/kaggle/input/rnp-miner-dataset/Test Data.csv\n/kaggle/input/rnp-miner-dataset/correct_predictions_per (1).csv\n/kaggle/input/rnp-miner-dataset/malicious.csv\n/kaggle/input/rnp-miner-dataset/Training Data.csv\n/kaggle/input/rnp-miner-dataset/correct_predictions_per (3).csv\n/kaggle/input/rnp-miner-dataset/normal_sdb1_format.txt\n/kaggle/input/rnp-miner-dataset/testing_queries.csv\n/kaggle/input/rnp-miner-dataset/normal.csv\n/kaggle/input/rnp-miner-dataset/training_queries.csv\n/kaggle/input/rnp-miner-dataset/normal_with_matrix.csv\n/kaggle/input/temp-data/testing_queries_for_15k.csv\n/kaggle/input/temp-data/skepticism_index_role4_for_5k.csv\n/kaggle/input/temp-data/skepticism_index_role0_for_5k.csv\n/kaggle/input/temp-data/training_queries_for_20k.csv\n/kaggle/input/temp-data/training_queries_for_15k.csv\n/kaggle/input/temp-data/training_queries_for_17.5k.csv\n/kaggle/input/temp-data/skepticism_index_role3_for_5k.csv\n/kaggle/input/temp-data/skepticism_index_role2_for_20k.csv\n/kaggle/input/temp-data/training_queries_for_5k.csv\n/kaggle/input/temp-data/skepticism_index_role2_for_10k.csv\n/kaggle/input/temp-data/skepticism_index_role3_for_10k.csv\n/kaggle/input/temp-data/skepticism_index_role3_for_20k.csv\n/kaggle/input/temp-data/testing_queries_for_17.5k.csv\n/kaggle/input/temp-data/correct_predictions_per_for_5k.csv\n/kaggle/input/temp-data/training_queries_for_22.5k.csv\n/kaggle/input/temp-data/testing_queries_for_5k.csv\n/kaggle/input/temp-data/skepticism_index_role1_for_10k.csv\n/kaggle/input/temp-data/skepticism_index_role1_for_5k.csv\n/kaggle/input/temp-data/skepticism_index_role4_for_10k.csv\n/kaggle/input/temp-data/training_queries_for_10k.csv\n/kaggle/input/temp-data/skepticism_index_role3_for_15k.csv\n/kaggle/input/temp-data/skepticism_index_role0_for_15k.csv\n/kaggle/input/temp-data/testing_queries_for_22.5k.csv\n/kaggle/input/temp-data/skepticism_index_role2_for_15k.csv\n/kaggle/input/temp-data/skepticism_index_role2_for_5k.csv\n/kaggle/input/temp-data/correct_predictions_per_for_20k.csv\n/kaggle/input/temp-data/skepticism_index_role4_for_15k.csv\n/kaggle/input/temp-data/skepticism_index_role1_for_15k.csv\n/kaggle/input/temp-data/testing_queries_for_20k.csv\n/kaggle/input/temp-data/skepticism_index_role0_for_20k.csv\n/kaggle/input/temp-data/correct_predictions_per_for_10k.csv\n/kaggle/input/temp-data/skepticism_index_role4_for_20k.csv\n/kaggle/input/temp-data/correct_predictions_per_for_15k.csv\n/kaggle/input/temp-data/testing_queries_for_10k.csv\n/kaggle/input/temp-data/skepticism_index_role0_for_10k.csv\n/kaggle/input/temp-data/skepticism_index_role1_for_20k.csv\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# import pandas as pd\n# from sklearn.model_selection import train_test_split\n\n# # Load dataset (Replace 'your_file.csv' with actual file name)\n# df = pd.read_csv('/kaggle/input/capsnet-lstm-dataset/train_data.csv')\n\n# # Step 1: Exclude first 1257 entries\n# df = df.iloc[1257:].reset_index(drop=True)\n\n# # Step 2: Shuffle the dataset\n# df = df.sample(frac=1, random_state=None).reset_index(drop=True)\n\n# # Step 3: Split into 80% train and 20% test\n# train_df, test_df = train_test_split(df, test_size=0.2, random_state=None, shuffle=False)  # Already shuffled\n\n# # Step 4: Save the split datasets\n# train_df.to_csv('/kaggle/working/train_data_shuffled.csv', index=False)\n# test_df.to_csv('/kaggle/working/test_data_shuffled.csv', index=False)\n\n# print(\"Files saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:32:05.779018Z","iopub.execute_input":"2025-04-05T19:32:05.779365Z","iopub.status.idle":"2025-04-05T19:32:05.783544Z","shell.execute_reply.started":"2025-04-05T19:32:05.779327Z","shell.execute_reply":"2025-04-05T19:32:05.782362Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import to_categorical\nimport ast  # Import the ast module\n\n# 1. Data Preprocessing\n\n# Load data from CSV\ndata = pd.read_csv('/kaggle/input/temp-data/training_queries_for_22.5k.csv')\n\n# Define all possible elements (vocabulary)\nvocabulary = [f\"{prefix}{num:02}\" for prefix in ['R', 'W'] for num in range(50)]\nnum_elements = len(vocabulary)\n\n# Create dictionaries for mapping\nword_to_index = {word: i for i, word in enumerate(vocabulary)}\nindex_to_word = {i: word for i, word in enumerate(vocabulary)}\n\n# Correctly encode the sequences (handling string representation of lists)\ndef encode_sequence(sequence_str):\n    try:\n        sequence_list = ast.literal_eval(sequence_str)  # Safely parse the string as a list\n        return [word_to_index[element] for element in sequence_list]\n    except (SyntaxError, ValueError):  # Handle potential errors in parsing\n        return []  # Or some other default value/handling for invalid sequences\n\ndata['encoded_sequence'] = data['query'].apply(encode_sequence)\n\n# Remove rows with empty encoded sequences (if any)\ndata = data[data['encoded_sequence'].apply(len) > 0]\n\n# Find the maximum sequence length (after removing potentially invalid sequences)\nmax_length = max(data['encoded_sequence'].apply(len))\n\n# Pad the sequences\npadded_sequences = pad_sequences(data['encoded_sequence'], maxlen=max_length, padding='post', value=0)\n\n# One-hot encode the sequences\none_hot_sequences = np.zeros((len(padded_sequences), max_length, num_elements))\nfor i, sequence in enumerate(padded_sequences):\n    for j, element in enumerate(sequence):\n        if element != 0:  # Ignore padding\n            one_hot_sequences[i, j, element] = 1\n\n# Prepare the labels (assuming roles are integers 0-4)\nroles = data['role'].values\nnum_roles = 5  # Get the number of unique roles\none_hot_labels = to_categorical(roles, num_classes=num_roles)\n\n# Example usage (print shapes to verify)\nprint(\"Padded Sequences shape:\", padded_sequences.shape)\nprint(\"One-Hot Sequences shape:\", one_hot_sequences.shape)\nprint(\"One-Hot Labels shape:\", one_hot_labels.shape)\nfrom sklearn.utils import shuffle\nX_train, y_train = shuffle(one_hot_sequences, one_hot_labels, random_state=None)\n# print(X_train.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:32:05.785383Z","iopub.execute_input":"2025-04-05T19:32:05.785748Z","iopub.status.idle":"2025-04-05T19:32:07.146009Z","shell.execute_reply.started":"2025-04-05T19:32:05.785713Z","shell.execute_reply":"2025-04-05T19:32:07.144809Z"}},"outputs":[{"name":"stdout","text":"Padded Sequences shape: (18000, 14)\nOne-Hot Sequences shape: (18000, 14, 100)\nOne-Hot Labels shape: (18000, 5)\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# import numpy as np\n# import tensorflow as tf\n# from tensorflow import keras\n# from tensorflow.keras import layers\n# from sklearn.model_selection import train_test_split\n# from tensorflow.keras.utils import to_categorical\n# import pandas as pd\n\n# # 3. Load and Preprocess the NEW test data (important: same preprocessing as training)\n# new_data_df = pd.read_csv(\"/kaggle/working/train_data_shuffled.csv\")  # Replace with your file name\n\n# all_elements = [f'R{i:02d}' for i in range(50)] + [f'W{i:02d}' for i in range(50)]\n# element_to_index = {element: idx for idx, element in enumerate(all_elements)}\n\n# def preprocess_sequence(sequence_string):\n#     tokens = sequence_string.strip(\"[]\").split(\",\")  # Remove brackets and split\n#     tokens = [token.strip('\"') for token in tokens] # Remove quotes\n#     index_sequence = [element_to_index.get(element) for element in tokens if element in element_to_index] # Handle unknown tokens\n#     return index_sequence\n\n# new_sequences = new_data_df['query'].tolist()\n# new_index_sequences = [preprocess_sequence(seq) for seq in new_sequences]\n\n# max_len = 14  # Make sure this is the same as your training data's max_len\n# new_padded_sequences = np.array([seq + [-1] * (max_len - len(seq)) for seq in new_index_sequences])\n\n# # One-hot encode (without padding token in the matrix)\n# one_hot_matrix = np.eye(len(all_elements))  # No +1 for padding!\n# new_one_hot_sequences = np.array([[one_hot_matrix[idx] if idx != -1 and idx is not None else np.zeros(len(all_elements)) for idx in seq] for seq in new_padded_sequences])\n\n# new_roles = new_data_df['role'].tolist()\n# num_classes = len(np.unique(new_roles)) # Get the number of classes dynamically\n# new_one_hot_roles = to_categorical(new_roles, num_classes=num_classes)\n\n# # 4. Prediction on NEW data\n# # 1. Slice the Data (Take only the first 4000 entries)\n# num_entries_to_take = 0\n# new_one_hot_sequences = new_one_hot_sequences[num_entries_to_take:]\n# new_one_hot_roles = new_one_hot_roles[num_entries_to_take:]\n\n# from sklearn.utils import shuffle\n# X_train, y_train = shuffle(new_one_hot_sequences, new_one_hot_roles, random_state=42)\n# # from sklearn.model_selection import train_test_split\n# # X_train, X_test, y_train, y_test = train_test_split(new_one_hot_sequences, new_one_hot_roles, test_size=0.2, random_state=42,shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:32:07.147597Z","iopub.execute_input":"2025-04-05T19:32:07.147973Z","iopub.status.idle":"2025-04-05T19:32:07.152461Z","shell.execute_reply.started":"2025-04-05T19:32:07.147933Z","shell.execute_reply":"2025-04-05T19:32:07.151284Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Conv1D, MaxPooling1D, UpSampling1D, GaussianNoise\nfrom tensorflow.keras.models import Model\n\n# Define input shape: 14 time-steps, 100 features\ninput_shape = (14, 100)\n\n# Encoder\ninput_seq = Input(shape=input_shape)\nembedded = Dense(32, activation='relu')(input_seq)  # Shape: (14, 32)\nx = Conv1D(32, 3, activation='relu', padding='same')(embedded)\nx = GaussianNoise(0.5)(x)\n\n# Adjust MaxPooling to achieve (8, 64) latent shape\nx = MaxPooling1D(2, padding='same', strides=1)(x)  # Reduce to (13, 32)\nx = MaxPooling1D(2, padding='same')(x)  # Reduce to (8, 32)\n\n# Convolutions to process features\nx = Conv1D(16, 3, activation='relu', padding='same')(x)\nx = Conv1D(8, 3, activation='relu', padding='same')(x)\n\n# Latent representation with (8, 64)\nencoded = Conv1D(64, 3, activation='relu', padding='same', name=\"latent\")(x)  # Now (8, 64)\n\n# Decoder\nx = UpSampling1D(2)(encoded)  # 8 -> 16\nx = Conv1D(16, 3, activation='relu', padding='same')(x)\n\n# Reduce to original 100 features per time step\ndecoded = Dense(100, activation='sigmoid')(x)  # Shape: (16, 100)\n\n# Build and compile the autoencoder model\nautoencoder = Model(input_seq, decoded)\nautoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nautoencoder.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:32:07.153657Z","iopub.execute_input":"2025-04-05T19:32:07.154039Z","iopub.status.idle":"2025-04-05T19:32:07.255315Z","shell.execute_reply.started":"2025-04-05T19:32:07.153997Z","shell.execute_reply":"2025-04-05T19:32:07.254284Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │           \u001b[38;5;34m3,232\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │           \u001b[38;5;34m3,104\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ gaussian_noise_1 (\u001b[38;5;33mGaussianNoise\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_2 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_3 (\u001b[38;5;33mMaxPooling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m16\u001b[0m)               │           \u001b[38;5;34m1,552\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │             \u001b[38;5;34m392\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ latent (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │           \u001b[38;5;34m1,600\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ up_sampling1d_1 (\u001b[38;5;33mUpSampling1D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)              │           \u001b[38;5;34m3,088\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │           \u001b[38;5;34m1,700\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,232</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ gaussian_noise_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,552</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">392</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ latent (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ up_sampling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling1D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,088</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,700</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,668\u001b[0m (57.30 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,668</span> (57.30 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,668\u001b[0m (57.30 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,668</span> (57.30 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nhistory = autoencoder.fit(X_train, X_train,  \n                          epochs=100,\n                          batch_size=32,\n                          validation_split=0.2)  # Set validation split (e.g., 20%)\n\n# Plot loss curves\nplt.plot(history.history['loss'], label='Train Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:32:07.257418Z","iopub.execute_input":"2025-04-05T19:32:07.257717Z","iopub.status.idle":"2025-04-05T19:37:09.245767Z","shell.execute_reply.started":"2025-04-05T19:32:07.257689Z","shell.execute_reply":"2025-04-05T19:37:09.244665Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.0158 - loss: 0.1964 - val_accuracy: 0.0299 - val_loss: 0.0566\nEpoch 2/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.0312 - loss: 0.0330 - val_accuracy: 0.0356 - val_loss: 0.0413\nEpoch 3/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0393 - loss: 0.0320 - val_accuracy: 0.0550 - val_loss: 0.0334\nEpoch 4/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.0644 - loss: 0.0304 - val_accuracy: 0.1047 - val_loss: 0.0294\nEpoch 5/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1177 - loss: 0.0279 - val_accuracy: 0.1612 - val_loss: 0.0261\nEpoch 6/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.1709 - loss: 0.0254 - val_accuracy: 0.2065 - val_loss: 0.0238\nEpoch 7/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2126 - loss: 0.0233 - val_accuracy: 0.2347 - val_loss: 0.0222\nEpoch 8/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2419 - loss: 0.0218 - val_accuracy: 0.2643 - val_loss: 0.0208\nEpoch 9/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.2657 - loss: 0.0206 - val_accuracy: 0.2886 - val_loss: 0.0195\nEpoch 10/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.2886 - loss: 0.0194 - val_accuracy: 0.3080 - val_loss: 0.0185\nEpoch 11/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3085 - loss: 0.0184 - val_accuracy: 0.3217 - val_loss: 0.0176\nEpoch 12/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3242 - loss: 0.0174 - val_accuracy: 0.3396 - val_loss: 0.0167\nEpoch 13/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3399 - loss: 0.0167 - val_accuracy: 0.3519 - val_loss: 0.0160\nEpoch 14/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3556 - loss: 0.0158 - val_accuracy: 0.3641 - val_loss: 0.0153\nEpoch 15/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3645 - loss: 0.0153 - val_accuracy: 0.3744 - val_loss: 0.0147\nEpoch 16/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3767 - loss: 0.0147 - val_accuracy: 0.3847 - val_loss: 0.0143\nEpoch 17/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3882 - loss: 0.0142 - val_accuracy: 0.3910 - val_loss: 0.0140\nEpoch 18/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3938 - loss: 0.0139 - val_accuracy: 0.4000 - val_loss: 0.0135\nEpoch 19/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4014 - loss: 0.0135 - val_accuracy: 0.4062 - val_loss: 0.0133\nEpoch 20/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4054 - loss: 0.0133 - val_accuracy: 0.4071 - val_loss: 0.0132\nEpoch 21/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4106 - loss: 0.0130 - val_accuracy: 0.4162 - val_loss: 0.0128\nEpoch 22/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4135 - loss: 0.0127 - val_accuracy: 0.4218 - val_loss: 0.0126\nEpoch 23/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4193 - loss: 0.0126 - val_accuracy: 0.4207 - val_loss: 0.0127\nEpoch 24/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4229 - loss: 0.0124 - val_accuracy: 0.4257 - val_loss: 0.0123\nEpoch 25/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4274 - loss: 0.0122 - val_accuracy: 0.4306 - val_loss: 0.0121\nEpoch 26/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4320 - loss: 0.0119 - val_accuracy: 0.4341 - val_loss: 0.0120\nEpoch 27/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4358 - loss: 0.0119 - val_accuracy: 0.4387 - val_loss: 0.0118\nEpoch 28/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4408 - loss: 0.0116 - val_accuracy: 0.4418 - val_loss: 0.0117\nEpoch 29/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4429 - loss: 0.0116 - val_accuracy: 0.4441 - val_loss: 0.0115\nEpoch 30/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4445 - loss: 0.0114 - val_accuracy: 0.4487 - val_loss: 0.0113\nEpoch 31/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4479 - loss: 0.0112 - val_accuracy: 0.4525 - val_loss: 0.0111\nEpoch 32/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4527 - loss: 0.0111 - val_accuracy: 0.4525 - val_loss: 0.0111\nEpoch 33/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4555 - loss: 0.0109 - val_accuracy: 0.4565 - val_loss: 0.0109\nEpoch 34/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4574 - loss: 0.0108 - val_accuracy: 0.4592 - val_loss: 0.0108\nEpoch 35/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4593 - loss: 0.0107 - val_accuracy: 0.4566 - val_loss: 0.0109\nEpoch 36/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4604 - loss: 0.0107 - val_accuracy: 0.4623 - val_loss: 0.0106\nEpoch 37/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4639 - loss: 0.0105 - val_accuracy: 0.4611 - val_loss: 0.0106\nEpoch 38/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4662 - loss: 0.0104 - val_accuracy: 0.4688 - val_loss: 0.0104\nEpoch 39/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4686 - loss: 0.0103 - val_accuracy: 0.4685 - val_loss: 0.0103\nEpoch 40/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4687 - loss: 0.0102 - val_accuracy: 0.4668 - val_loss: 0.0103\nEpoch 41/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4685 - loss: 0.0102 - val_accuracy: 0.4704 - val_loss: 0.0102\nEpoch 42/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4735 - loss: 0.0100 - val_accuracy: 0.4704 - val_loss: 0.0102\nEpoch 43/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4750 - loss: 0.0099 - val_accuracy: 0.4723 - val_loss: 0.0101\nEpoch 44/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4748 - loss: 0.0098 - val_accuracy: 0.4738 - val_loss: 0.0100\nEpoch 45/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4777 - loss: 0.0097 - val_accuracy: 0.4744 - val_loss: 0.0101\nEpoch 46/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4784 - loss: 0.0097 - val_accuracy: 0.4776 - val_loss: 0.0099\nEpoch 47/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4769 - loss: 0.0097 - val_accuracy: 0.4778 - val_loss: 0.0098\nEpoch 48/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4791 - loss: 0.0096 - val_accuracy: 0.4773 - val_loss: 0.0098\nEpoch 49/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4820 - loss: 0.0095 - val_accuracy: 0.4765 - val_loss: 0.0098\nEpoch 50/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4811 - loss: 0.0095 - val_accuracy: 0.4818 - val_loss: 0.0097\nEpoch 51/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4824 - loss: 0.0094 - val_accuracy: 0.4818 - val_loss: 0.0096\nEpoch 52/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4838 - loss: 0.0094 - val_accuracy: 0.4835 - val_loss: 0.0095\nEpoch 53/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4844 - loss: 0.0094 - val_accuracy: 0.4837 - val_loss: 0.0095\nEpoch 54/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4858 - loss: 0.0093 - val_accuracy: 0.4865 - val_loss: 0.0094\nEpoch 55/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4861 - loss: 0.0093 - val_accuracy: 0.4856 - val_loss: 0.0093\nEpoch 56/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4874 - loss: 0.0093 - val_accuracy: 0.4852 - val_loss: 0.0093\nEpoch 57/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4874 - loss: 0.0091 - val_accuracy: 0.4862 - val_loss: 0.0093\nEpoch 58/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4885 - loss: 0.0092 - val_accuracy: 0.4851 - val_loss: 0.0094\nEpoch 59/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4893 - loss: 0.0091 - val_accuracy: 0.4859 - val_loss: 0.0094\nEpoch 60/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4916 - loss: 0.0090 - val_accuracy: 0.4904 - val_loss: 0.0091\nEpoch 61/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4908 - loss: 0.0090 - val_accuracy: 0.4861 - val_loss: 0.0093\nEpoch 62/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4936 - loss: 0.0088 - val_accuracy: 0.4888 - val_loss: 0.0092\nEpoch 63/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4910 - loss: 0.0090 - val_accuracy: 0.4895 - val_loss: 0.0092\nEpoch 64/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4943 - loss: 0.0089 - val_accuracy: 0.4912 - val_loss: 0.0091\nEpoch 65/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4942 - loss: 0.0088 - val_accuracy: 0.4874 - val_loss: 0.0093\nEpoch 66/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4946 - loss: 0.0089 - val_accuracy: 0.4919 - val_loss: 0.0091\nEpoch 67/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4927 - loss: 0.0088 - val_accuracy: 0.4904 - val_loss: 0.0091\nEpoch 68/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4960 - loss: 0.0087 - val_accuracy: 0.4940 - val_loss: 0.0090\nEpoch 69/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4955 - loss: 0.0087 - val_accuracy: 0.4909 - val_loss: 0.0090\nEpoch 70/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4991 - loss: 0.0087 - val_accuracy: 0.4924 - val_loss: 0.0090\nEpoch 71/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4959 - loss: 0.0088 - val_accuracy: 0.4945 - val_loss: 0.0089\nEpoch 72/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4984 - loss: 0.0086 - val_accuracy: 0.4931 - val_loss: 0.0090\nEpoch 73/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4991 - loss: 0.0086 - val_accuracy: 0.4935 - val_loss: 0.0089\nEpoch 74/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4994 - loss: 0.0085 - val_accuracy: 0.4951 - val_loss: 0.0088\nEpoch 75/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4992 - loss: 0.0086 - val_accuracy: 0.4955 - val_loss: 0.0088\nEpoch 76/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5004 - loss: 0.0085 - val_accuracy: 0.4956 - val_loss: 0.0088\nEpoch 77/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4990 - loss: 0.0085 - val_accuracy: 0.4961 - val_loss: 0.0088\nEpoch 78/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5005 - loss: 0.0085 - val_accuracy: 0.4966 - val_loss: 0.0087\nEpoch 79/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5007 - loss: 0.0084 - val_accuracy: 0.4974 - val_loss: 0.0087\nEpoch 80/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5013 - loss: 0.0084 - val_accuracy: 0.4993 - val_loss: 0.0087\nEpoch 81/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5041 - loss: 0.0083 - val_accuracy: 0.5002 - val_loss: 0.0086\nEpoch 82/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5027 - loss: 0.0084 - val_accuracy: 0.4992 - val_loss: 0.0086\nEpoch 83/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5023 - loss: 0.0084 - val_accuracy: 0.4988 - val_loss: 0.0086\nEpoch 84/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5041 - loss: 0.0083 - val_accuracy: 0.5002 - val_loss: 0.0086\nEpoch 85/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5040 - loss: 0.0083 - val_accuracy: 0.4995 - val_loss: 0.0086\nEpoch 86/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5047 - loss: 0.0082 - val_accuracy: 0.4996 - val_loss: 0.0085\nEpoch 87/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5048 - loss: 0.0083 - val_accuracy: 0.4980 - val_loss: 0.0086\nEpoch 88/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5049 - loss: 0.0083 - val_accuracy: 0.5009 - val_loss: 0.0085\nEpoch 89/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5071 - loss: 0.0081 - val_accuracy: 0.5001 - val_loss: 0.0086\nEpoch 90/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5057 - loss: 0.0082 - val_accuracy: 0.5021 - val_loss: 0.0084\nEpoch 91/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5070 - loss: 0.0081 - val_accuracy: 0.5040 - val_loss: 0.0083\nEpoch 92/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5066 - loss: 0.0081 - val_accuracy: 0.5025 - val_loss: 0.0083\nEpoch 93/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5086 - loss: 0.0080 - val_accuracy: 0.4998 - val_loss: 0.0085\nEpoch 94/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5089 - loss: 0.0080 - val_accuracy: 0.5032 - val_loss: 0.0083\nEpoch 95/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5068 - loss: 0.0080 - val_accuracy: 0.5043 - val_loss: 0.0084\nEpoch 96/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5088 - loss: 0.0080 - val_accuracy: 0.5024 - val_loss: 0.0083\nEpoch 97/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5084 - loss: 0.0081 - val_accuracy: 0.5050 - val_loss: 0.0083\nEpoch 98/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5100 - loss: 0.0079 - val_accuracy: 0.5061 - val_loss: 0.0083\nEpoch 99/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5100 - loss: 0.0079 - val_accuracy: 0.5027 - val_loss: 0.0083\nEpoch 100/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5083 - loss: 0.0080 - val_accuracy: 0.5033 - val_loss: 0.0083\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\n# Get reconstructed output\ndecoded_output = autoencoder.predict(X_train)\n\n# Select a sample sequence\nindex = np.random.randint(0, len(X_train))\noriginal = X_train[index]\nreconstructed = decoded_output[index]\n\n# Plot the original and reconstructed sequence\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.imshow(original.T, aspect='auto', cmap='viridis')\nplt.title(\"Original Sequence\")\nplt.subplot(1, 2, 2)\nplt.imshow(reconstructed.T, aspect='auto', cmap='viridis')\nplt.title(\"Reconstructed Sequence\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:37:09.247252Z","iopub.execute_input":"2025-04-05T19:37:09.247547Z","iopub.status.idle":"2025-04-05T19:37:11.889819Z","shell.execute_reply.started":"2025-04-05T19:37:09.247523Z","shell.execute_reply":"2025-04-05T19:37:11.888635Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 2 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# Extract the encoder model\nencoder = Model(inputs=autoencoder.input, outputs=autoencoder.get_layer(\"latent\").output)\n# Get the encoded (compressed) features\nencoded_features = encoder.predict(X_train)\nprint(encoded_features.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:37:11.890638Z","iopub.execute_input":"2025-04-05T19:37:11.890922Z","iopub.status.idle":"2025-04-05T19:37:13.505344Z","shell.execute_reply.started":"2025-04-05T19:37:11.890899Z","shell.execute_reply":"2025-04-05T19:37:13.504231Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m563/563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n(18000, 7, 64)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.optimizers import Adam\nimport pandas as pd\n\n# ... (your data loading and preprocessing code as before, resulting in X_train, X_test, y_train, y_test)\n\n# 1. LSTM Model with Attention (same as before)\nmodel_input = keras.Input(shape=(7, 64))  # Timesteps, Features\n\n# LSTM layers\nlstm1 = layers.LSTM(64, return_sequences=True)(model_input)\ndropout1 = layers.Dropout(0.2)(lstm1)\nlstm2 = layers.LSTM(32, return_sequences=True)(dropout1)  # Return sequences for attention\ndropout2 = layers.Dropout(0.2)(lstm2)\n\n# Attention mechanism\nattention_output = layers.Attention()([lstm2, lstm2])  # Self-attention\n\n# Flatten the attention output\nattention_flatten = layers.Flatten()(attention_output)\n\n# Dense layers after attention\ndense1 = layers.Dense(32, activation='relu')(attention_flatten)\ndropout3 = layers.Dropout(0.2)(dense1)\n\noutput = layers.Dense(y_train.shape[1], activation='softmax')(dropout3)  # Output shape matches labels\n\nmodel = keras.Model(inputs=model_input, outputs=output)\nmodel.compile(\n    loss=\"categorical_crossentropy\",\n    optimizer=Adam(),\n    metrics=[\"accuracy\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:37:13.506485Z","iopub.execute_input":"2025-04-05T19:37:13.506854Z","iopub.status.idle":"2025-04-05T19:37:13.584722Z","shell.execute_reply.started":"2025-04-05T19:37:13.506818Z","shell.execute_reply":"2025-04-05T19:37:13.583689Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"#Train LSTM on extracted features\nprint(encoded_features.shape)\nmodel.fit(encoded_features, y_train, epochs=100, batch_size=32, validation_split = 0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:37:13.585824Z","iopub.execute_input":"2025-04-05T19:37:13.586231Z","iopub.status.idle":"2025-04-05T19:43:39.248651Z","shell.execute_reply.started":"2025-04-05T19:37:13.586175Z","shell.execute_reply":"2025-04-05T19:43:39.247580Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"(18000, 7, 64)\nEpoch 1/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.7054 - loss: 0.7707 - val_accuracy: 0.8967 - val_loss: 0.3039\nEpoch 2/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9067 - loss: 0.2770 - val_accuracy: 0.9278 - val_loss: 0.2022\nEpoch 3/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9292 - loss: 0.2112 - val_accuracy: 0.9367 - val_loss: 0.1843\nEpoch 4/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9401 - loss: 0.1770 - val_accuracy: 0.9436 - val_loss: 0.1646\nEpoch 5/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9521 - loss: 0.1430 - val_accuracy: 0.9356 - val_loss: 0.1838\nEpoch 6/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9570 - loss: 0.1303 - val_accuracy: 0.9514 - val_loss: 0.1302\nEpoch 7/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9610 - loss: 0.1154 - val_accuracy: 0.9597 - val_loss: 0.1339\nEpoch 8/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9673 - loss: 0.1083 - val_accuracy: 0.9519 - val_loss: 0.1468\nEpoch 9/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9689 - loss: 0.0928 - val_accuracy: 0.9569 - val_loss: 0.1273\nEpoch 10/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9721 - loss: 0.0873 - val_accuracy: 0.9672 - val_loss: 0.1028\nEpoch 11/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9719 - loss: 0.0819 - val_accuracy: 0.9672 - val_loss: 0.1077\nEpoch 12/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9777 - loss: 0.0682 - val_accuracy: 0.9542 - val_loss: 0.1400\nEpoch 13/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9782 - loss: 0.0649 - val_accuracy: 0.9631 - val_loss: 0.1096\nEpoch 14/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9781 - loss: 0.0636 - val_accuracy: 0.9644 - val_loss: 0.1100\nEpoch 15/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9768 - loss: 0.0649 - val_accuracy: 0.9642 - val_loss: 0.1078\nEpoch 16/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9807 - loss: 0.0568 - val_accuracy: 0.9706 - val_loss: 0.0962\nEpoch 17/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9844 - loss: 0.0497 - val_accuracy: 0.9653 - val_loss: 0.1024\nEpoch 18/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9825 - loss: 0.0504 - val_accuracy: 0.9597 - val_loss: 0.1270\nEpoch 19/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9808 - loss: 0.0620 - val_accuracy: 0.9708 - val_loss: 0.1029\nEpoch 20/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0504 - val_accuracy: 0.9692 - val_loss: 0.0994\nEpoch 21/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9851 - loss: 0.0449 - val_accuracy: 0.9686 - val_loss: 0.1109\nEpoch 22/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9830 - loss: 0.0527 - val_accuracy: 0.9672 - val_loss: 0.0935\nEpoch 23/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9849 - loss: 0.0493 - val_accuracy: 0.9725 - val_loss: 0.0872\nEpoch 24/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9859 - loss: 0.0393 - val_accuracy: 0.9664 - val_loss: 0.1097\nEpoch 25/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9838 - loss: 0.0471 - val_accuracy: 0.9686 - val_loss: 0.0947\nEpoch 26/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9887 - loss: 0.0366 - val_accuracy: 0.9692 - val_loss: 0.0936\nEpoch 27/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9862 - loss: 0.0414 - val_accuracy: 0.9708 - val_loss: 0.0843\nEpoch 28/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0260 - val_accuracy: 0.9678 - val_loss: 0.1035\nEpoch 29/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.0372 - val_accuracy: 0.9658 - val_loss: 0.1386\nEpoch 30/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9860 - loss: 0.0426 - val_accuracy: 0.9717 - val_loss: 0.1010\nEpoch 31/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9879 - loss: 0.0328 - val_accuracy: 0.9697 - val_loss: 0.1168\nEpoch 32/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9892 - loss: 0.0323 - val_accuracy: 0.9733 - val_loss: 0.1002\nEpoch 33/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9891 - loss: 0.0331 - val_accuracy: 0.9736 - val_loss: 0.1064\nEpoch 34/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9909 - loss: 0.0291 - val_accuracy: 0.9606 - val_loss: 0.1238\nEpoch 35/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9869 - loss: 0.0392 - val_accuracy: 0.9675 - val_loss: 0.1097\nEpoch 36/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9877 - loss: 0.0345 - val_accuracy: 0.9753 - val_loss: 0.0921\nEpoch 37/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9942 - loss: 0.0195 - val_accuracy: 0.9736 - val_loss: 0.0980\nEpoch 38/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0259 - val_accuracy: 0.9683 - val_loss: 0.1303\nEpoch 39/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9902 - loss: 0.0346 - val_accuracy: 0.9747 - val_loss: 0.1047\nEpoch 40/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0300 - val_accuracy: 0.9739 - val_loss: 0.0921\nEpoch 41/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.0267 - val_accuracy: 0.9756 - val_loss: 0.0821\nEpoch 42/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9893 - loss: 0.0328 - val_accuracy: 0.9667 - val_loss: 0.1174\nEpoch 43/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9907 - loss: 0.0295 - val_accuracy: 0.9719 - val_loss: 0.1078\nEpoch 44/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9949 - loss: 0.0175 - val_accuracy: 0.9728 - val_loss: 0.1057\nEpoch 45/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9933 - loss: 0.0218 - val_accuracy: 0.9725 - val_loss: 0.1050\nEpoch 46/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9901 - loss: 0.0292 - val_accuracy: 0.9756 - val_loss: 0.0937\nEpoch 47/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0223 - val_accuracy: 0.9728 - val_loss: 0.1072\nEpoch 48/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9911 - loss: 0.0277 - val_accuracy: 0.9689 - val_loss: 0.1302\nEpoch 49/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9912 - loss: 0.0246 - val_accuracy: 0.9703 - val_loss: 0.1174\nEpoch 50/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9937 - loss: 0.0222 - val_accuracy: 0.9736 - val_loss: 0.0865\nEpoch 51/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9909 - loss: 0.0264 - val_accuracy: 0.9736 - val_loss: 0.1000\nEpoch 52/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9927 - loss: 0.0266 - val_accuracy: 0.9739 - val_loss: 0.0985\nEpoch 53/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.0255 - val_accuracy: 0.9739 - val_loss: 0.1046\nEpoch 54/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0188 - val_accuracy: 0.9781 - val_loss: 0.0815\nEpoch 55/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9920 - loss: 0.0232 - val_accuracy: 0.9742 - val_loss: 0.0878\nEpoch 56/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9932 - loss: 0.0208 - val_accuracy: 0.9706 - val_loss: 0.1024\nEpoch 57/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9934 - loss: 0.0192 - val_accuracy: 0.9667 - val_loss: 0.1218\nEpoch 58/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9909 - loss: 0.0290 - val_accuracy: 0.9719 - val_loss: 0.1147\nEpoch 59/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9913 - loss: 0.0251 - val_accuracy: 0.9756 - val_loss: 0.0902\nEpoch 60/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0143 - val_accuracy: 0.9722 - val_loss: 0.1048\nEpoch 61/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9905 - loss: 0.0265 - val_accuracy: 0.9725 - val_loss: 0.0994\nEpoch 62/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0142 - val_accuracy: 0.9761 - val_loss: 0.1046\nEpoch 63/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9923 - loss: 0.0213 - val_accuracy: 0.9664 - val_loss: 0.1469\nEpoch 64/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9922 - loss: 0.0229 - val_accuracy: 0.9739 - val_loss: 0.1028\nEpoch 65/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9926 - loss: 0.0230 - val_accuracy: 0.9706 - val_loss: 0.1221\nEpoch 66/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.0280 - val_accuracy: 0.9744 - val_loss: 0.1175\nEpoch 67/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.0150 - val_accuracy: 0.9758 - val_loss: 0.1194\nEpoch 68/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9925 - loss: 0.0225 - val_accuracy: 0.9731 - val_loss: 0.1094\nEpoch 69/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9948 - loss: 0.0141 - val_accuracy: 0.9744 - val_loss: 0.1167\nEpoch 70/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9947 - loss: 0.0168 - val_accuracy: 0.9739 - val_loss: 0.0999\nEpoch 71/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0178 - val_accuracy: 0.9753 - val_loss: 0.1069\nEpoch 72/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9926 - loss: 0.0230 - val_accuracy: 0.9761 - val_loss: 0.0972\nEpoch 73/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9938 - loss: 0.0178 - val_accuracy: 0.9742 - val_loss: 0.1263\nEpoch 74/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9963 - loss: 0.0130 - val_accuracy: 0.9731 - val_loss: 0.1318\nEpoch 75/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9931 - loss: 0.0196 - val_accuracy: 0.9725 - val_loss: 0.1124\nEpoch 76/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9946 - loss: 0.0163 - val_accuracy: 0.9714 - val_loss: 0.1082\nEpoch 77/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0235 - val_accuracy: 0.9728 - val_loss: 0.1138\nEpoch 78/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9950 - loss: 0.0175 - val_accuracy: 0.9744 - val_loss: 0.1196\nEpoch 79/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9952 - loss: 0.0166 - val_accuracy: 0.9772 - val_loss: 0.1220\nEpoch 80/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9940 - loss: 0.0186 - val_accuracy: 0.9658 - val_loss: 0.1484\nEpoch 81/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9894 - loss: 0.0347 - val_accuracy: 0.9739 - val_loss: 0.0946\nEpoch 82/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0102 - val_accuracy: 0.9794 - val_loss: 0.1068\nEpoch 83/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0126 - val_accuracy: 0.9747 - val_loss: 0.0948\nEpoch 84/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9924 - loss: 0.0231 - val_accuracy: 0.9744 - val_loss: 0.1021\nEpoch 85/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9966 - loss: 0.0112 - val_accuracy: 0.9789 - val_loss: 0.0989\nEpoch 86/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.0154 - val_accuracy: 0.9728 - val_loss: 0.1094\nEpoch 87/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9925 - loss: 0.0219 - val_accuracy: 0.9775 - val_loss: 0.0983\nEpoch 88/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0163 - val_accuracy: 0.9758 - val_loss: 0.1034\nEpoch 89/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9958 - loss: 0.0153 - val_accuracy: 0.9750 - val_loss: 0.1025\nEpoch 90/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9917 - loss: 0.0232 - val_accuracy: 0.9806 - val_loss: 0.0740\nEpoch 91/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9944 - loss: 0.0159 - val_accuracy: 0.9806 - val_loss: 0.0883\nEpoch 92/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9968 - loss: 0.0091 - val_accuracy: 0.9742 - val_loss: 0.0990\nEpoch 93/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9935 - loss: 0.0225 - val_accuracy: 0.9767 - val_loss: 0.0911\nEpoch 94/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9928 - loss: 0.0221 - val_accuracy: 0.9783 - val_loss: 0.0887\nEpoch 95/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9926 - loss: 0.0208 - val_accuracy: 0.9744 - val_loss: 0.1042\nEpoch 96/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9962 - loss: 0.0118 - val_accuracy: 0.9744 - val_loss: 0.1001\nEpoch 97/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9954 - loss: 0.0148 - val_accuracy: 0.9750 - val_loss: 0.1111\nEpoch 98/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9941 - loss: 0.0172 - val_accuracy: 0.9742 - val_loss: 0.1072\nEpoch 99/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9955 - loss: 0.0137 - val_accuracy: 0.9769 - val_loss: 0.0975\nEpoch 100/100\n\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9943 - loss: 0.0154 - val_accuracy: 0.9764 - val_loss: 0.1149\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7fdf81376050>"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# from tensorflow.keras.preprocessing.sequence import pad_sequences\n# from tensorflow.keras.utils import to_categorical\n# import ast  # Import the ast module\n\n# # 1. Data Preprocessing\n\n# # Load data from CSV\n# data = pd.read_csv('/kaggle/input/capsnet-lstm-dataset/testing_queries.csv')\n\n# # Define all possible elements (vocabulary)\n# vocabulary = [f\"{prefix}{num:02}\" for prefix in ['R', 'W'] for num in range(50)]\n# num_elements = len(vocabulary)\n\n# # Create dictionaries for mapping\n# word_to_index = {word: i for i, word in enumerate(vocabulary)}\n# index_to_word = {i: word for i, word in enumerate(vocabulary)}\n\n# # Correctly encode the sequences (handling string representation of lists)\n# def encode_sequence(sequence_str):\n#     try:\n#         sequence_list = ast.literal_eval(sequence_str)  # Safely parse the string as a list\n#         return [word_to_index[element] for element in sequence_list]\n#     except (SyntaxError, ValueError):  # Handle potential errors in parsing\n#         return []  # Or some other default value/handling for invalid sequences\n\n# data['encoded_sequence'] = data['query'].apply(encode_sequence)\n\n# # Remove rows with empty encoded sequences (if any)\n# data = data[data['encoded_sequence'].apply(len) > 0]\n\n# # Find the maximum sequence length (after removing potentially invalid sequences)\n# max_length = max(data['encoded_sequence'].apply(len))\n\n# # Pad the sequences\n# padded_sequences = pad_sequences(data['encoded_sequence'], maxlen=max_length, padding='post', value=0)\n\n# # One-hot encode the sequences\n# one_hot_sequences = np.zeros((len(padded_sequences), max_length, num_elements))\n# for i, sequence in enumerate(padded_sequences):\n#     for j, element in enumerate(sequence):\n#         if element != 0:  # Ignore padding\n#             one_hot_sequences[i, j, element] = 1\n\n# # Prepare the labels (assuming roles are integers 0-4)\n# roles = data['role'].values\n# num_roles = 5  # Get the number of unique roles\n# one_hot_labels = to_categorical(roles, num_classes=num_roles)\n\n# # Example usage (print shapes to verify)\n# print(\"Padded Sequences shape:\", padded_sequences.shape)\n# print(\"One-Hot Sequences shape:\", one_hot_sequences.shape)\n# print(\"One-Hot Labels shape:\", one_hot_labels.shape)\n# from sklearn.utils import shuffle\n# X_test, y_test = shuffle(one_hot_sequences, one_hot_labels, random_state=None)\n# # print(X_train.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:43:39.249905Z","iopub.execute_input":"2025-04-05T19:43:39.250380Z","iopub.status.idle":"2025-04-05T19:43:39.255259Z","shell.execute_reply.started":"2025-04-05T19:43:39.250283Z","shell.execute_reply":"2025-04-05T19:43:39.254270Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# #/kaggle/input/capsnet-lstm-dataset/train_data.csv\n\n# import numpy as np\n# import tensorflow as tf\n# from tensorflow import keras\n# from tensorflow.keras import layers\n# from sklearn.model_selection import train_test_split\n# from tensorflow.keras.utils import to_categorical\n# import pandas as pd\n\n# # 3. Load and Preprocess the NEW test data (important: same preprocessing as training)\n# new_data_df = pd.read_csv(\"/kaggle/working/test_data_shuffled.csv\")  # Replace with your file name\n\n# all_elements = [f'R{i:02d}' for i in range(50)] + [f'W{i:02d}' for i in range(50)]\n# element_to_index = {element: idx for idx, element in enumerate(all_elements)}\n\n# def preprocess_sequence(sequence_string):\n#     tokens = sequence_string.strip(\"[]\").split(\",\")  # Remove brackets and split\n#     tokens = [token.strip('\"') for token in tokens] # Remove quotes\n#     index_sequence = [element_to_index.get(element) for element in tokens if element in element_to_index] # Handle unknown tokens\n#     return index_sequence\n\n# new_sequences = new_data_df['query'].tolist()\n# new_index_sequences = [preprocess_sequence(seq) for seq in new_sequences]\n\n# max_len = 14  # Make sure this is the same as your training data's max_len\n# new_padded_sequences = np.array([seq + [-1] * (max_len - len(seq)) for seq in new_index_sequences])\n\n# # One-hot encode (without padding token in the matrix)\n# one_hot_matrix = np.eye(len(all_elements))  # No +1 for padding!\n# new_one_hot_sequences = np.array([[one_hot_matrix[idx] if idx != -1 and idx is not None else np.zeros(len(all_elements)) for idx in seq] for seq in new_padded_sequences])\n\n# new_roles = new_data_df['role'].tolist()\n# num_classes = len(np.unique(new_roles)) # Get the number of classes dynamically\n# new_one_hot_roles = to_categorical(new_roles, num_classes=num_classes)\n\n# # 4. Prediction on NEW data\n# # 1. Slice the Data (Take only the first 4000 entries)\n# num_entries_to_take = 0\n# new_one_hot_sequences = new_one_hot_sequences[num_entries_to_take:]\n# new_one_hot_roles = new_one_hot_roles[num_entries_to_take:]\n\n# from sklearn.utils import shuffle\n# X_test, y_test = shuffle(new_one_hot_sequences, new_one_hot_roles, random_state=42)\n# print(X_test.shape)","metadata":{"trusted":true,"scrolled":true,"execution":{"iopub.status.busy":"2025-04-05T19:43:39.256330Z","iopub.execute_input":"2025-04-05T19:43:39.256664Z","iopub.status.idle":"2025-04-05T19:43:39.279588Z","shell.execute_reply.started":"2025-04-05T19:43:39.256626Z","shell.execute_reply":"2025-04-05T19:43:39.278330Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# encoded_features_test = encoder.predict(X_test)\n# print(encoded_features_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:43:39.280597Z","iopub.execute_input":"2025-04-05T19:43:39.280885Z","iopub.status.idle":"2025-04-05T19:43:39.299099Z","shell.execute_reply.started":"2025-04-05T19:43:39.280856Z","shell.execute_reply":"2025-04-05T19:43:39.298064Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"# import os\n# import numpy as np\n# import pandas as pd\n# from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n# from sklearn.preprocessing import LabelEncoder\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n\n# OUTPUT_DIR = \"/kaggle/working/\"\n# predictions = model.predict(encoded_features_test)\n# predicted_labels = np.argmax(predictions, axis=1)\n# actual_labels = np.argmax(y_test, axis=1)\n# correct_indices = np.where(predicted_labels == actual_labels)[0]\n# output_df = data.iloc[correct_indices].copy()\n# output_path = os.path.join(OUTPUT_DIR, \"correct_predictions.csv\")\n# output_df.to_csv(output_path, index=False)\n# precision = precision_score(actual_labels, predicted_labels, average='weighted')\n# recall = recall_score(actual_labels, predicted_labels, average='weighted')\n# f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n# accuracy = len(output_df)/len(encoded_features_test)\n# print(f\"\\nEvaluation Metrics:\")\n# print(f\"Accuracy: {accuracy:.2%}\")\n# print(f\"Precision: {precision:.2%}\")\n# print(f\"Recall: {recall:.2%}\")\n# print(f\"F1-Score: {f1:.2%}\")\n# print(f\"\\nSaved {len(output_df)}/{len(encoded_features_test)} correctly predicted queries to {output_path}\")\n\n# #confusion matrix \n# def plot_confusion_matrix(y_true, y_pred, classes):\n#     cm = confusion_matrix(y_true, y_pred)\n#     plt.figure(figsize=(10, 8))\n#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n#                 xticklabels=classes, yticklabels=classes)\n#     plt.xlabel('Predicted')\n#     plt.ylabel('Actual')\n#     plt.title('Confusion Matrix')\n#     plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'))\n#     plt.show()\n\n# # Get class names (assuming you have them)\n# class_names = np.unique(data['role'])  # Update if your label column has different name\n# plot_confusion_matrix(actual_labels, predicted_labels, class_names)\n\n# # Optional: Save full metrics report\n# metrics_df = pd.DataFrame({\n#     'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n#     'Value': [accuracy, precision, recall, f1]\n# })\n# metrics_df.to_csv(os.path.join(OUTPUT_DIR, 'evaluation_metrics.csv'), index=False)\n\n# # List files in output directory\n# print(\"\\nFiles in output directory:\")\n# print(os.listdir(OUTPUT_DIR))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:43:39.302233Z","iopub.execute_input":"2025-04-05T19:43:39.302566Z","iopub.status.idle":"2025-04-05T19:43:39.318741Z","shell.execute_reply.started":"2025-04-05T19:43:39.302528Z","shell.execute_reply":"2025-04-05T19:43:39.317612Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"# import os\n# import numpy as np\n# import pandas as pd\n# from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n# from sklearn.preprocessing import LabelEncoder\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n\n# OUTPUT_DIR = \"/kaggle/working/\"\n# predictions = model.predict(encoded_features_test)\n# predicted_labels = np.argmax(predictions, axis=1)\n# actual_labels = np.argmax(y_test, axis=1)\n# correct_indices = np.where(predicted_labels == actual_labels)[0]\n# output_df = new_data_df.iloc[correct_indices].copy()\n# output_path = os.path.join(OUTPUT_DIR, \"correct_predictions.csv\")\n# output_df.to_csv(output_path, index=False)\n# precision = precision_score(actual_labels, predicted_labels, average='weighted')\n# recall = recall_score(actual_labels, predicted_labels, average='weighted')\n# f1 = f1_score(actual_labels, predicted_labels, average='weighted')\n# accuracy = len(output_df)/len(encoded_features_test)\n# print(f\"\\nEvaluation Metrics:\")\n# print(f\"Accuracy: {accuracy:.2%}\")\n# print(f\"Precision: {precision:.2%}\")\n# print(f\"Recall: {recall:.2%}\")\n# print(f\"F1-Score: {f1:.2%}\")\n# print(f\"\\nSaved {len(output_df)}/{len(encoded_features_test)} correctly predicted queries to {output_path}\")\n\n# #confusion matrix \n# def plot_confusion_matrix(y_true, y_pred, classes):\n#     cm = confusion_matrix(y_true, y_pred)\n#     plt.figure(figsize=(10, 8))\n#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n#                 xticklabels=classes, yticklabels=classes)\n#     plt.xlabel('Predicted')\n#     plt.ylabel('Actual')\n#     plt.title('Confusion Matrix')\n#     plt.savefig(os.path.join(OUTPUT_DIR, 'confusion_matrix.png'))\n#     plt.show()\n\n# # Get class names (assuming you have them)\n# class_names = np.unique(new_data_df['role'])  # Update if your label column has different name\n# plot_confusion_matrix(actual_labels, predicted_labels, class_names)\n\n# # Optional: Save full metrics report\n# metrics_df = pd.DataFrame({\n#     'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n#     'Value': [accuracy, precision, recall, f1]\n# })\n# metrics_df.to_csv(os.path.join(OUTPUT_DIR, 'evaluation_metrics.csv'), index=False)\n\n# # List files in output directory\n# print(\"\\nFiles in output directory:\")\n# print(os.listdir(OUTPUT_DIR))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:43:39.320257Z","iopub.execute_input":"2025-04-05T19:43:39.320656Z","iopub.status.idle":"2025-04-05T19:43:39.341018Z","shell.execute_reply.started":"2025-04-05T19:43:39.320617Z","shell.execute_reply":"2025-04-05T19:43:39.339813Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# loss, accuracy = model.evaluate(encoded_features_test, y_test)\n# print(f\"Test Accuracy: {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:43:39.342062Z","iopub.execute_input":"2025-04-05T19:43:39.342473Z","iopub.status.idle":"2025-04-05T19:43:39.362169Z","shell.execute_reply.started":"2025-04-05T19:43:39.342433Z","shell.execute_reply":"2025-04-05T19:43:39.360943Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# from tensorflow.keras.preprocessing.sequence import pad_sequences\n# import ast\n\n# # Load vocabulary and mappings (same as training)\n# vocabulary = [f\"{prefix}{num:02}\" for prefix in ['R', 'W'] for num in range(50)]\n# word_to_index = {word: i for i, word in enumerate(vocabulary)}\n\n# # Function to preprocess a single query (same as training)\n# def preprocess_query(query_str):\n#     try:\n#         sequence_list = ast.literal_eval(query_str)  # Parse string to list\n#         encoded_seq = [word_to_index[element] for element in sequence_list]\n#     except (SyntaxError, ValueError, KeyError):\n#         return None  # Handle invalid queries\n        \n#     padded_seq = pad_sequences([encoded_seq], maxlen=max_length, padding='post', value=0)\n    \n#     # One-hot encode (same as training)\n#     one_hot_seq = np.zeros((1, max_length, len(vocabulary)))\n#     for j, element in enumerate(padded_seq[0]):\n#         if element != 0:\n#             one_hot_seq[0, j, element] = 1\n#     return one_hot_seq\n\n# # Function to predict and validate\n# def predict_and_validate(query, true_role, model):\n#     # Preprocess query\n#     X = preprocess_query(query)\n#     if X is None:\n#         print(\"Invalid query format!\")\n#         return\n    \n#     # Predict\n#     encoded_features_test = encoder.predict(X)\n#     pred_prob = model.predict(encoded_features_test)\n#     pred_role = np.argmax(pred_prob, axis=1)[0]\n    \n#     # Check if prediction matches true_role\n#     is_correct = (pred_role == true_role)\n#     print(f\"Query: {query}\")\n#     print(f\"Predicted Role: {pred_role} | True Role: {true_role}\")\n#     print(f\"Result: {'✅ True' if is_correct else '❌ False'}\")\n#     return is_correct\n\n# # Example Usage\n# query = \"['R48', 'R46', 'R45', 'R31', 'R31', 'R26', 'W20', 'W24', 'W25', 'R42', 'R46']\"  # Example input (must be string representation of a list)\n# true_role = 3  # Example role (integer 0-4)\n# predict_and_validate(query, true_role, model)  # Replace `model` with your trained model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:43:39.363438Z","iopub.execute_input":"2025-04-05T19:43:39.363759Z","iopub.status.idle":"2025-04-05T19:43:39.379748Z","shell.execute_reply.started":"2025-04-05T19:43:39.363728Z","shell.execute_reply":"2025-04-05T19:43:39.378697Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# from tensorflow.keras.preprocessing.sequence import pad_sequences\n# import ast\n\n# # Load vocabulary and mappings\n# vocabulary = [f\"{prefix}{num:02}\" for prefix in ['R', 'W'] for num in range(50)]\n# word_to_index = {word: i for i, word in enumerate(vocabulary)}\n# max_length = max_length\n\n# # Function to preprocess a single query\n# def preprocess_query(query_str):\n#     try:\n#         sequence_list = ast.literal_eval(query_str)  # Parse string to list\n#         encoded_seq = [word_to_index[element] for element in sequence_list if element in word_to_index]\n#     except (SyntaxError, ValueError, KeyError):\n#         return None  # Skip invalid queries\n        \n#     padded_seq = pad_sequences([encoded_seq], maxlen=max_length, padding='post', value=0)\n    \n#     # One-hot encode\n#     one_hot_seq = np.zeros((1, max_length, len(vocabulary)))\n#     for j, element in enumerate(padded_seq[0]):\n#         if element != 0:\n#             one_hot_seq[0, j, element] = 1\n#     return one_hot_seq\n\n# # Function to process the entire input file\n# def process_input_file(input_path, output_path, encoder, model):\n#     # Read input file\n#     df = pd.read_csv(input_path)  # Adjust if file format differs (e.g., Excel, JSON)\n    \n#     correct_predictions = []\n    \n#     for _, row in df.iterrows():\n#         query = row['query']  # Replace with your query column name\n#         true_role = row['role']     # Replace with your label column name\n        \n#         # Preprocess and predict\n#         X = preprocess_query(query)\n#         if X is None:\n#             continue  # Skip invalid queries\n        \n#         encoded_features = encoder.predict(X , verbose = 0)\n#         pred_prob = model.predict(encoded_features ,  verbose = 0)\n#         pred_role = np.argmax(pred_prob, axis=1)[0]\n        \n#         # Store if prediction matches true role\n#         if pred_role == true_role:\n#             correct_predictions.append(row.to_dict())\n    \n#     # Save correct predictions to output file\n#     if correct_predictions:\n#         pd.DataFrame(correct_predictions).to_csv(output_path, index=False)\n#         print(f\"Saved {len(correct_predictions)} correct predictions to {output_path}\")\n#     else:\n#         print(\"No correct predictions found.\")\n\n\n# input_path = \"/kaggle/input/capsnet-lstm-dataset/testing_queries.csv\"\n# output_path = \"/kaggle/working/correct_predictions_per.csv\"\n# process_input_file(input_path, output_path, encoder, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:43:39.380714Z","iopub.execute_input":"2025-04-05T19:43:39.380966Z","iopub.status.idle":"2025-04-05T19:43:39.404239Z","shell.execute_reply.started":"2025-04-05T19:43:39.380945Z","shell.execute_reply":"2025-04-05T19:43:39.402933Z"},"scrolled":true},"outputs":[],"execution_count":38},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# from tensorflow.keras.preprocessing.sequence import pad_sequences\n# import ast\n\n# # Load vocabulary and mappings\n# vocabulary = [f\"{prefix}{num:02}\" for prefix in ['R', 'W'] for num in range(50)]\n# word_to_index = {word: i for i, word in enumerate(vocabulary)}\n# max_length = max_length\n\n# def preprocess_query(query_str):\n#     try:\n#         sequence_list = ast.literal_eval(query_str)  # Parse string to list\n#         encoded_seq = [word_to_index[element] for element in sequence_list if element in word_to_index]\n#     except (SyntaxError, ValueError, KeyError):\n#         return None  # Skip invalid queries\n        \n#     padded_seq = pad_sequences([encoded_seq], maxlen=max_length, padding='post', value=0)\n    \n#     # One-hot encode\n#     one_hot_seq = np.zeros((1, max_length, len(vocabulary)))\n#     for j, element in enumerate(padded_seq[0]):\n#         if element != 0:\n#             one_hot_seq[0, j, element] = 1\n#     return one_hot_seq\n\n# def process_input_file(input_path, output_path, encoder, model, max_length=50):\n    \n#     # Read input file\n#     df = pd.read_csv(input_path)\n    \n#     # Verify required columns exist\n#     if 'query' not in df.columns or 'role' not in df.columns:\n#         raise ValueError(\"Input CSV must contain 'query' and 'role' columns\")\n    \n#     # Initialize list to store all rows with predictions\n#     results = []\n#     correct_count = 0\n    \n#     for _, row in df.iterrows():\n#         query = row['query']\n#         true_role = row['role']\n        \n#         # Preprocess and predict\n#         X = preprocess_query(query)\n#         if X is None:\n#             # For invalid queries, mark as incorrect prediction (1)\n#             results.append({**row.to_dict(), 'predicted_class': 1})\n#             continue\n        \n#         encoded_features = encoder.predict(X, verbose=0)\n#         pred_prob = model.predict(encoded_features, verbose=0)\n#         pred_role = np.argmax(pred_prob, axis=1)[0]\n        \n#         # Determine if prediction was correct (0) or incorrect (1)\n#         prediction_status = 0 if pred_role == true_role else 1\n#         if prediction_status == 0:\n#             correct_count += 1\n        \n#         # Add the original row data with the new predicted_class column\n#         results.append({**row.to_dict(), 'predicted_class': prediction_status})\n    \n#     # Convert results to DataFrame\n#     result_df = pd.DataFrame(results)\n    \n#     # Save to output file\n#     result_df.to_csv(output_path, index=False)\n    \n#     # Calculate and print accuracy\n#     total_rows = len(result_df)\n#     accuracy = (correct_count / total_rows) * 100 if total_rows > 0 else 0\n#     print(f\"Processed {total_rows} rows. Accuracy: {accuracy:.2f}%\")\n#     print(f\"Saved results with predictions to {output_path}\")\n\n# input_path = \"/kaggle/input/capsnet-lstm-dataset/testing_queries.csv\"\n# output_path = \"/kaggle/working/correct_predictions_per.csv\"\n# process_input_file(input_path, output_path, encoder, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:43:39.405326Z","iopub.execute_input":"2025-04-05T19:43:39.405626Z","iopub.status.idle":"2025-04-05T19:43:39.425316Z","shell.execute_reply.started":"2025-04-05T19:43:39.405599Z","shell.execute_reply":"2025-04-05T19:43:39.424134Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport ast\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Load vocabulary and mappings\nvocabulary = [f\"{prefix}{num:02}\" for prefix in ['R', 'W'] for num in range(50)]\nword_to_index = {word: i for i, word in enumerate(vocabulary)}\nmax_length = max_length  # Make sure this is defined in your code\n\ndef preprocess_query(query_str):\n    try:\n        sequence_list = ast.literal_eval(query_str)\n        encoded_seq = [word_to_index[element] for element in sequence_list if element in word_to_index]\n    except (SyntaxError, ValueError, KeyError):\n        return None\n        \n    padded_seq = pad_sequences([encoded_seq], maxlen=max_length, padding='post', value=0)\n    \n    one_hot_seq = np.zeros((1, max_length, len(vocabulary)))\n    for j, element in enumerate(padded_seq[0]):\n        if element != 0:\n            one_hot_seq[0, j, element] = 1\n    return one_hot_seq\n\ndef process_and_analyze(input_path, output_path, encoder, model):\n    # --- Processing Phase ---\n    df = pd.read_csv(input_path)\n    \n    if 'query' not in df.columns or 'role' not in df.columns:\n        raise ValueError(\"Input CSV must contain 'query' and 'role' columns\")\n    \n    results = []\n\n    \n    for _, row in df.iterrows():\n        query = row['query']\n        true_role = row['role']\n        \n        X = preprocess_query(query)\n        if X is None:\n            continue\n        \n        encoded_features = encoder.predict(X, verbose=0)\n        pred_prob = model.predict(encoded_features, verbose=0)\n        pred_role = np.argmax(pred_prob, axis=1)[0]\n\n        prediction_status = 0\n        \n        if pred_role == true_role:\n            prediction_status = 0 \n        else:\n            if true_role == 0 or true_role == 2 : \n                prediction_status = 1\n            else:\n                prediction_status = 0\n        results.append({**row.to_dict(), 'predicted_class': prediction_status})\n    \n    result_df = pd.DataFrame(results)\n    result_df.to_csv(output_path, index=False)\n    \n\n# Example usage\ninput_path = \"/kaggle/input/temp-data/testing_queries_for_22.5k.csv\"\noutput_path = 'correct_predictions_per_for_22.5k.csv'\n\nresult_df, role_counts = process_and_analyze(input_path, output_path, encoder, model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T19:43:39.426162Z","iopub.execute_input":"2025-04-05T19:43:39.426502Z","iopub.status.idle":"2025-04-05T19:54:01.199923Z","shell.execute_reply.started":"2025-04-05T19:43:39.426475Z","shell.execute_reply":"2025-04-05T19:54:01.198723Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-40-b81057aec13a>\u001b[0m in \u001b[0;36m<cell line: 70>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'correct_predictions_per_for_22.5k.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m \u001b[0mresult_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_and_analyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"],"ename":"TypeError","evalue":"cannot unpack non-iterable NoneType object","output_type":"error"}],"execution_count":40},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}